web.link<-"http://espn.go.com/nba/gamecast?gameId=400830060"
web.link %>%
html_node("playId") %>%
html_text() %>%
as.numeric()
web.link %>%
html_node("playId")%>%
html_text()
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
lego_movie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_nodes("#titleCast .itemprop span") %>%
html_text()
install.packages("scrapeR")
library(scrapeR)
scrape(url="http://espn.go.com/nba/gamecast?gameId=400830076",object=NULL,file=NULL,chunkSize=50,maxSleep=5,
userAgent=unlist(options("HTTPUserAgent")),follow=FALSE,
headers=TRUE,parse=TRUE,isXML=FALSE,.encoding=integer(),
verbose=FALSE)
scrape(url="http://espn.go.com/nba/gamecast?gameId=400830056",object=NULL,file=NULL,chunkSize=50,maxSleep=5,
userAgent=unlist(options("HTTPUserAgent")),follow=FALSE,
headers=TRUE,parse=TRUE,isXML=FALSE,.encoding=integer(),
verbose=FALSE)
library("rvest")
htmlpage <- html("http://forecast.weather.gov/MapClick.php?lat=42.31674913306716&lon=-71.42487878862437&site=all&smap=1#.VRsEpZPF84I")
forecasthtml <- html_nodes(htmlpage, "#detailed-forecast-body b , .forecast-text")
forecast <- html_text(forecasthtml)
paste(forecast, collapse =" ")
?html
?"html_nodes"
?split
library(scrapeR)
raw<-scrape(url="http://espn.go.com/nba/gamecast?gameId=400830056",object=NULL,file=NULL,chunkSize=50,maxSleep=5,
userAgent=unlist(options("HTTPUserAgent")),follow=FALSE,
headers=TRUE,parse=TRUE,isXML=FALSE,.encoding=integer(),
verbose=FALSE)
first.pass<-split(raw,"<script>")
length(first.pass)
raw<-scrape(url="http://espn.go.com/nba/gamecast?gameId=400830056",object=NULL,file=NULL,chunkSize=50,maxSleep=5,
userAgent=unlist(options("HTTPUserAgent")),follow=FALSE,
headers=TRUE,parse=FALSE,isXML=FALSE,.encoding=integer(),
verbose=FALSE)
first.pass<-split(raw,"<script>")
length(first.pass)
library(XML)
library(RSelenium)
install.packages("RSelenium")
library(XML)
library(RSelenium)
url <- "espn.go.com/nba/gamecast?gameId=400830060"
checkForServer()        # download Selenium Server, if not already presnet
startServer()           # start Selenium Server
remDr <- remoteDriver() # instantiates a new driver
remDr$open()            # open connection
remDr$navigate(url)     # grab and process the page (including scripts)
doc   <- htmlParse(remDr$getPageSource()[[1]])
library(XML)
url<-"http://espn.go.com/nba/gamecast?gameId=400830060"
doc <- htmlTreeParse(url, useInternalNodes=TRUE)
doc
url.list <- xpathSApply(doc, "//a[contains(@script, 'var settings')]")
url.list
length(doc)
doc<-split(doc,"<Script>")
library(scrapeR)
raw<-scrape(url="http://espn.go.com/nba/gamecast?gameId=400830056",object=NULL,file=NULL,chunkSize=50,maxSleep=5,
userAgent=unlist(options("HTTPUserAgent")),follow=FALSE,
headers=TRUE,parse=FALSE,isXML=FALSE,.encoding=integer(),
verbose=FALSE)
first.pass<-split(raw,"<script>")
length(first.pass)
raw
library(htmltools)
library(XML)
# URL of interest:
mps <- "http://espn.go.com/nba/gamecast?gameId=400830060"
split(mps,"<script>")
library(XML)
# URL of interest:
mps <- "http://espn.go.com/nba/gamecast?gameId=400830060"
split(mps,"<script>")
# URL of interest:
mps <- "http://espn.go.com/nba/gamecast?gameId=400830060"
# parse the document for R representation:
mps.doc <- htmlParse(mps)
split(mps,"<script>")
load("C:/Users/nmvenuti/Downloads/dsm_decomposed.RData")
flag.summary<-matrix(
c(100,110,120,5,6,7,8,9,10),
nrow = 3,
ncol=3
)
#get frequency table for the 3 email categories, convert to data frame:
a<-flag.summary[,1]
b<-flag.summary[,2]
c<-flag.summary[,3]
flag.summary<-data.frame(cbind(a,b,c))
names(flag.summary)<-c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid")
#add another column that contains the total number of non_gov emails in each cluster
flag.summary$total_non_gov<-flag.summary$dont_contain_state.gov_or_Sid+flag.summary$dont_contain_state.gov_but_Sid
flag.summary$ratio<-(flag.summary[,2]+flag.summary[,3])/flag.summary[,1]
head(flag.summary)
barplot(flag.summary)
barplot(as.matrix(flag.summary))
barplot(table(flag.summary))
library(ggplot2)
df <- read.table(text = "       Input Rtime Rcost Rsolutions  Btime Bcost
1   12-proc.     1    36     614425     40    36
2   15-proc.     1    51     534037     50    51
3    18-proc     5    62    1843820     66    66
4    20-proc     4    68    1645581 104400    73
5 20-proc(l)     4    64    1658509  14400    65
6    21-proc    10    78    3923623 453600    82",header = TRUE,sep = "")
df
dfm <- melt(df[,c('Input','Rtime','Btime')],id.vars = 1)
library(reshape)
library(reshape2)
dfm <- melt(df[,c('Input','Rtime','Btime')],id.vars = 1)
dfm
ggplot(dfm,aes(x = Input,y = value)) +
geom_bar(aes(fill = variable),position = "dodge") +
scale_y_log10()
ggplot(dfm,aes(x = Input,y = value)) +
geom_bar(aes(fill = variable),position = "dodge") +
scale_y_log10())
ggplot(dfm,aes(x = Input,y = value)) +
geom_bar(aes(fill = variable),position = "dodge")
df <- read.table(text = "       Input Rtime Rcost Rsolutions  Btime Bcost
1   12-proc.     1    36     614425     40    36
2   15-proc.     1    51     534037     50    51
3    18-proc     5    62    1843820     66    66
4    20-proc     4    68    1645581 104400    73
5 20-proc(l)     4    64    1658509  14400    65
6    21-proc    10    78    3923623 453600    82",header = TRUE,sep = "")
df
dfm <- melt(df[,c('Input','Rtime','Btime')],id.vars = 1)
dfm
ggplot(dfm,aes(x = Input,y = value)) +
geom_bar(aes(fill = variable),position = "dodge")
ggplot(dfm,aes(x = Input,y = value))
library(ggplot)
?barplot
barplot(table(flag.summary))
barplot(as.matrix(flag.summary))
?barplot
barplot(as.matrix(flag.summary),beside = TRUE)
barplot(t(table(flag.summary$contain_state.gov,flag.summary$dont_contain_state.gov_but_Sid,flag.summary$dont_contain_state.gov_or_Sid))
,beside = TRUE)
barplot(as.matrix(flag.summary$contain_state.gov,flag.summary$dont_contain_state.gov_but_Sid,flag.summary$dont_contain_state.gov_or_Sid),beside = TRUE)
barplot(t(as.matrix(flag.summary$contain_state.gov,flag.summary$dont_contain_state.gov_but_Sid,flag.summary$dont_contain_state.gov_or_Sid))
,beside = TRUE)
barplot(as.matrix(flag.summary[,1:3])
,beside = TRUE)
flags<-melt(flag.summary[,c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid")],id.vars = 1)
barplot(flags,beside = TRUE)
barplot(as.matrix(flags),beside = TRUE)
head(flags)
a<-flag.summary[,1]
b<-flag.summary[,2]
c<-flag.summary[,3]
flag.summary<-data.frame(cbind(a,b,c))
names(flag.summary)<-c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid")
flags<-melt(flag.summary[,c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid")],id.vars = 1)
head(flags)
barplot(as.matrix(flags),beside = TRUE)
?melt
flags<-melt(flag.summary,id.vars = 1)
head(flags)
flags<-melt(flag.summary)
head(flags)
barplot(as.matrix(flags),beside = TRUE)
flags
flag.summary$id<-names(flag.summary)
barplot(as.matrix(flag.summary),beside = TRUE)
barplot(flag.summary,beside = TRUE)
head(flag.summary)
flag.summary$id<-rownames(flag.summary)
head(flag.summary)
barplot(flag.summary,beside = TRUE)
barplot(as.matrix(flag.summary),beside = TRUE)
library(lattice)
flags<-melt(flag.summary)
head(flags)
barchart(value~id,data=flags,groups=variable,
scales=list(x=list(rot=90,cex=0.8)))
?barchart
barchart(value~id,data=flags,groups=variable)
barchart(value~id,data=flags,groups=variable, col=c('g','y','r'))
library(RColorBrewer)
display.brewer.all()
library(RColorBrewer)
display.brewer.all()
barchart(value~id,data=flags,groups=variable, col=c('green','yellow','red'))
barchart(value~id,data=flags,groups=variable, col=c('darkgreen','yellow','red'))
barchart(value~id,data=flags,groups=variable, col=c('darkgreen','yellow','red'),
ylab="Count")
barchart(value~id,data=flags,groups=variable, col=c('darkgreen','yellow','red'),
ylab="Count", xlab="Cluster")
?barchart
barchart(value~id,data=flags,groups=variable, col=c('darkgreen','yellow','red'),
ylab="Count", xlab="Cluster", legend.text = c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid") )
barchart(value~id,data=flags,groups=variable, col=c('darkgreen','yellow','red'),
ylab="Count", xlab="Cluster", main ="Email Types by Cluster",
legend.text = c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid"))
barchart(value~id,data=flags,groups=variable, col=c('darkgreen','yellow','red'),
ylab="Count", xlab="Cluster", main ="Email Types by Cluster",
auto.key=list(space='right'), scales=list(x=list(rot=45)))
barchart(value~id,data=flags,groups=variable,
ylab="Count", xlab="Cluster", main ="Email Types by Cluster",
auto.key=list(space='right'), scales=list(x=list(rot=45)),
par.settings=list(superpose.polygon=list(col=c('darkgreen','yellow','red'))))
library(lattice)
library(reshape2)
flag.summary<-matrix(
c(100,110,120,5,6,7,8,9,10),
nrow = 3,
ncol=3
)
#get frequency table for the 3 email categories, convert to data frame:
a<-flag.summary[,1]
b<-flag.summary[,2]
c<-flag.summary[,3]
flag.summary<-data.frame(cbind(a,b,c))
names(flag.summary)<-c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid")
#add another column that contains the total number of non_gov emails in each cluster
flag.summary$total_non_gov<-flag.summary$dont_contain_state.gov_or_Sid+flag.summary$dont_contain_state.gov_but_Sid
flag.summary$ratio<-(flag.summary[,2]+flag.summary[,3])/flag.summary[,1]
flag.summary$id<-rownames(flag.summary)
head(flag.summary)
flags<-melt(flag.summary)
barchart(value~id,data=flags,groups=variable,
ylab="Count", xlab="Cluster", main ="Email Types by Cluster",
auto.key=list(space='right'), scales=list(x=list(rot=45)),
par.settings=list(superpose.polygon=list(col=c('darkgreen','yellow','red'))))
library(lattice)
library(reshape2)
flag.summary<-matrix(
c(100,110,120,5,6,7,8,9,10),
nrow = 3,
ncol=3
)
#get frequency table for the 3 email categories, convert to data frame:
a<-flag.summary[,1]
b<-flag.summary[,2]
c<-flag.summary[,3]
flag.summary<-data.frame(cbind(a,b,c))
names(flag.summary)<-c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid")
#add another column that contains the total number of non_gov emails in each cluster
flag.summary$total_non_gov<-flag.summary$dont_contain_state.gov_or_Sid+flag.summary$dont_contain_state.gov_but_Sid
flag.summary$ratio<-(flag.summary[,2]+flag.summary[,3])/flag.summary[,1]
flags<-flag.summary
flags$id<-rownames(flags)
flags<-melt(flags)
barchart(value~id,data=flags,groups=variable,
ylab="Count", xlab="Cluster", main ="Email Types by Cluster",
auto.key=list(space='right'), scales=list(x=list(rot=45)),
par.settings=list(superpose.polygon=list(col=c('darkgreen','yellow','red'))))
library(lattice)
library(reshape2)
flag.summary<-matrix(
c(100,110,120,5,6,7,8,9,10),
nrow = 3,
ncol=3
)
#get frequency table for the 3 email categories, convert to data frame:
a<-flag.summary[,1]
b<-flag.summary[,2]
c<-flag.summary[,3]
flag.summary<-data.frame(cbind(a,b,c))
names(flag.summary)<-c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid")
#add another column that contains the total number of non_gov emails in each cluster
flag.summary$total_non_gov<-flag.summary$dont_contain_state.gov_or_Sid+flag.summary$dont_contain_state.gov_but_Sid
flag.summary$ratio<-(flag.summary[,2]+flag.summary[,3])/flag.summary[,1]
flags<-flag.summary
flags$id<-rownames(flags)
flags<-melt(flags)
barchart(value~id,data=flags,groups=variable,
ylab="Count", xlab="Cluster", main ="Email Types by Cluster",
auto.key=list(space='right'), scales=list(x=list(rot=45)),
par.settings=list(superpose.polygon=list(col=c('darkgreen','yellow','red'))))
library(lattice)
library(reshape2)
flag.summary<-matrix(
c(100,110,120,5,6,7,8,9,10),
nrow = 3,
ncol=3
)
#get frequency table for the 3 email categories, convert to data frame:
a<-flag.summary[,1]
b<-flag.summary[,2]
c<-flag.summary[,3]
flag.summary<-data.frame(cbind(a,b,c))
names(flag.summary)<-c("contain_state.gov","dont_contain_state.gov_but_Sid","dont_contain_state.gov_or_Sid")
#add another column that contains the total number of non_gov emails in each cluster
flag.summary$total_non_gov<-flag.summary$dont_contain_state.gov_or_Sid+flag.summary$dont_contain_state.gov_but_Sid
flag.summary$ratio<-(flag.summary[,2]+flag.summary[,3])/flag.summary[,1]
flags<-flag.summary[,1:3]
flags$id<-rownames(flags)
flags<-melt(flags)
barchart(value~id,data=flags,groups=variable,
ylab="Count", xlab="Cluster", main ="Email Types by Cluster",
auto.key=list(space='right'), scales=list(x=list(rot=45)),
par.settings=list(superpose.polygon=list(col=c('darkgreen','yellow','red'))))
install.packages("ISLR")
library(ISLR)
names(Smarket)
dim(Smarket)
summary(Smarket)
cor(Smarket[,-9])
attach(Smarket)
?attach
plot(Volume)
data=Smarket, family = binomial)
glm.fit <-glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume,data=Smarket, family = binomial)
summary(glm.fit)
coef(glm.fit)
contrasts(Direction)
glm.pribs<-predict(glm.fit, type = "response")
glm.probs<-predict(glm.fit, type = "response")
head(glm.probs)
glm.pred<-rep("Down",length(glm.probs))
glm.pred[glm.probs>.5]<-"Up"
table(glm.pred,Directon)
table(glm.pred,Direction)
1-mean(glm.pred==Direction)
train<-Year<2005
Smarket.2005<-Smarlet[!train,]
Smarket.2005<-Smarket[!train,]
Direction.2005<-Direction[!train]
glm.fit<-glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data = Smarket,
family = binomial, subset = train)
glm.probs<-predict(glm.fit,Smarket.2005, type = "response")
glm.pred<-rep("Down",length(train))
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction.2005)
glm.pred<-rep("Down",length(train))
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction.2005)
glm.pred<-rep("Down",length(gln.probs))
glm.pred<-rep("Down",length(glm.probs))
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction.2005)
1-mean(glm.pred==Direction)
1-mean(glm.pred==Direction.2005)
glm.fit<-glm(Direction~Lag1+Lag2, data = Smarket,
family = binomial, subset = train)
glm.probs<-predict(glm.fit,Smarket.2005, type = "response")
#recreate prediction analysis on test set
glm.pred<-rep("Down",length(glm.probs))
glm.pred[glm.probs>.5]="Up"
table(glm.pred,Direction.2005)
1-mean(glm.pred==Direction.2005)
predict (glm.fit ,newdata =data.frame(Lag1=c(1.2 ,1.5) ,
Lag2=c(1.1 , -0.8) ),type =" response ")
predict (glm.fit ,newdata =data.frame(Lag1=c(1.2 ,1.5) ,
Lag2=c(1.1 , -0.8) ),type ="response")
library(MASS)
lda.fit<-lda(Direction~Lag1+Lag2, data=Smarket, subset=train)
lda.fit
plot(lda.fit)
lda.pred<-predict(lda.fit,Smarket.2005)
names(lda.pred)
lda.class<-lda.pred$class
table(lda.class,Direction.2005)
1-mean(lda.class==Direction.2005)
qda.fit<-qda(Direction~Lag1+Lag2, data = Smarket, subset = train)
qda.fit
qda.class<-predict(qda.fit,Smarket.2005)$class
table(qda.class,Direction.2005)
1-mean(qda.class==Direction.2005)
library(class)
train.X<-cbind(Lag1,Lag2)[train,]
test.X<-cbind(Lag1,Lag2)[!train,]
train.Direction<-direction[train,]
train.Direction<-Direction[train,]
train.Direction<-Direction[train]
set.seed(1)
knn.pred<-knn(train.X,test.X,train.Direction, k=1)
table(knn.pred,Direction.2005)
1-mean(knn.pred==Direction.2005)
knn.pred<-knn(train.X,test.X,train.Direction, k=3)
#Check prediction rate
table(knn.pred,Direction.2005)
1-mean(knn.pred==Direction.2005)
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
preprocessDocuments(filepath)
?clusterEvalQ
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
#Test this shit son!
preprocessDocuments(filepath)
clusterExport(preprocessing,c('removePunctuationExceptPeriod','individualizeEndOfSent,simpleTokenizer,removeEmptyStrings))
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
#Test this shit son!
preprocessDocuments(filepath)
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
#Test this shit son!
preprocessDocuments(filepath)
cl
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
numCores <- 1
cl <- makeCluster(mc <- getOption("cl.cores", numCores))
clusterEvalQ(cl, {source("preprocessing.R")})
preprocessDocuments(filepath)
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
numCores <- 2
cl <- makeCluster(mc <- getOption("cl.cores", numCores))
clusterEvalQ(cl, {source("preprocessing.R")})
#Test this shit son!
preprocessDocuments(filepath)
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
numCores <- 2
cl <- makeCluster(mc <- getOption("cl.cores", numCores))
clusterEvalQ(cl, {source("preprocessing.R")})
#Test this shit son!
preprocessDocuments(filepath)
getwd
getwd()
?paste0
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
numCores <- 2
cl <- makeCluster(mc <- getOption("cl.cores", numCores))
clusterEvalQ(cl, {source("preprocessing.R")})
#Test this shit son!
preprocessDocuments(filepath)
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
numCores <- 2
cl <- makeCluster(mc <- getOption("cl.cores", numCores))
clusterEvalQ(cl, {source("preprocessing.R")})
#Test this shit son!
preprocessDocuments(filepath)
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
numCores <- 2
cl <- makeCluster(mc <- getOption("cl.cores", numCores))
clusterEvalQ(cl, {source("preprocessing.R")})
#Test this shit son!
preprocessDocuments(filepath)
##################
#####Test Doc#####
##################
setwd("~/GitHub/dsicapstone-predicting_extremism/nmvenuti_sandbox")
source("preprocessing.R")
#Test preprocessing
filepath="C:/Users/nmvenuti/Desktop/UVA MSDS/Capstone/webscraping westboro/sermons"
numCores <- 2
cl <- makeCluster(mc <- getOption("cl.cores", numCores))
clusterEvalQ(cl, {source("preprocessing.R")})
#Test this shit son!
preprocessDocuments(filepath)
